{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taBOSk4HKwZp"
      },
      "outputs": [],
      "source": [
        "# import libraries here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szQFlMDMJYEh"
      },
      "outputs": [],
      "source": [
        "# Write your proposed solution code here. Create more code cells if you find it necessary\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomResizedCrop(256, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "]) \n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(type=\"cuda\", index=0)\n",
        "else:\n",
        "    device = torch.device(type=\"cpu\", index=0)\n",
        "\n",
        "# Load Dataset\n",
        "dataset = torchvision.datasets.ImageFolder(root='./Images', transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "class_names = dataset.classes\n",
        "\n",
        "\n",
        "# Split into train/val/test\n",
        "total_size = len(dataset)\n",
        "test_size = int(0.2 * total_size)\n",
        "train_val_size = total_size - test_size\n",
        "\n",
        "train_val_dataset, test_dataset = random_split(dataset, [train_val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "# K-Fold Cross-Validation\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define Custom CNN\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        \n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128 * 8 * 8, 256),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 21)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define an existing CNN ResNet18\n",
        "\n",
        "def resnetModel(strategy='fine_tune'):\n",
        "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 21)\n",
        "\n",
        "    if strategy == 'feature_extractor':\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def trainModel(model, train_loader, val_loader, epochs=30, lr=0.01, momentum=0.9, weight_decay=0.00001):\n",
        "    \"\"\"\n",
        "    Trains a model using SGD optimizer.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1)\n",
        "\n",
        "    train_accuracies = []\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_accuracy = correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_accuracy = correct / total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.3f} | Train Acc: {train_accuracy:.3f} | Validation Loss: {val_loss:.3f} | Validation Acc: {val_accuracy:.3f}\")\n",
        "\n",
        "    return model, train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluating the CNNs\n",
        "\n",
        "def evaluateModel(model, test_loader, return_predictions=False):\n",
        "    \"\"\"Evaluates the model and optionally returns predictions and true labels.\"\"\"\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    print(f\"Precision: {prec:.3f} | Recall: {rec:.3f} | F1 Score: {f1:.3f}\")\n",
        "\n",
        "    if return_predictions:\n",
        "        return y_true, y_pred, acc, prec, rec, f1\n",
        "\n",
        "    return None\n",
        "\n",
        "def denormalize(tensor, mean, std):\n",
        "    mean = torch.tensor(mean).view(3, 1, 1)\n",
        "    std = torch.tensor(std).view(3, 1, 1)\n",
        "\n",
        "    return tensor * std + mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluating the custom CNN\n",
        "\n",
        "def crossValidation(dataset, k=5, batch_size=32):\n",
        "    \"\"\"Performs k-fold cross-validation and generates confusion matrix and plots for all folds.\"\"\"\n",
        "\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    all_y_true, all_y_pred = [], []\n",
        "    all_train_losses, all_val_losses = [], []\n",
        "    all_train_accuracies, all_val_accuracies = [], []\n",
        "    all_accs, all_precs, all_recs, all_f1s = [], [], [], []\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(kf.split(dataset)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_dataset = Subset(dataset, train_idx)\n",
        "        valid_dataset = Subset(dataset, valid_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        model_custom = CustomCNN()\n",
        "        model_custom, train_losses, val_losses, train_accuracies, val_accuracies = trainModel(model_custom, train_loader, valid_loader)\n",
        "        y_true, y_pred, acc, prec, rec, f1 = evaluateModel(model_custom, valid_loader, return_predictions=True)\n",
        "\n",
        "        all_train_losses.append(train_losses)\n",
        "        all_val_losses.append(val_losses)\n",
        "        all_train_accuracies.append(train_accuracies)\n",
        "        all_val_accuracies.append(val_accuracies)\n",
        "        all_accs.append(acc)\n",
        "        all_precs.append(prec)\n",
        "        all_recs.append(rec)\n",
        "        all_f1s.append(f1)\n",
        "\n",
        "        all_y_true.extend(y_true)\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "        # Example image display for the current fold\n",
        "        example_loader = DataLoader(valid_dataset, batch_size=5, shuffle=True)\n",
        "        images, labels = next(iter(example_loader))\n",
        "        images = images.to(device)\n",
        "        denorm_images = denormalize(images.cpu(), mean=[-0.1497, 0.00008, 0.0594], std=[1.0153, 0.9942, 0.9404])\n",
        "        outputs = model_custom(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 5, figsize=(20, 8))\n",
        "        for idx in range(5):\n",
        "            img = denorm_images[idx].permute(1, 2, 0).numpy()\n",
        "            pred_label = class_names[preds[idx].item()]\n",
        "            actual_label = class_names[labels[idx].item()]\n",
        "            axes[idx].imshow(img)\n",
        "            axes[idx].set_title(f\"Pred: {pred_label} | Actual: {actual_label}\", fontsize=8)\n",
        "            axes[idx].axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    # Generate and display the overall confusion matrix\n",
        "    print(\"Overall Confusion Matrix:\")\n",
        "    confusion_matrix_all = confusion_matrix(all_y_true, all_y_pred)\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    sns.heatmap(confusion_matrix_all, annot=True, fmt=\"d\", cmap=\"twilight\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Overall Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_train_losses = np.mean(np.array(all_train_losses), axis=0)\n",
        "    avg_val_losses = np.mean(np.array(all_val_losses), axis=0)\n",
        "    avg_train_accuracies = np.mean(np.array(all_train_accuracies), axis=0)\n",
        "    avg_val_accuracies = np.mean(np.array(all_val_accuracies), axis=0)\n",
        "    avg_train_accuracies1 = np.mean((all_train_accuracies))\n",
        "    avg_val_accuracies2 = np.mean((all_val_accuracies))\n",
        "    avg_acc = np.mean(all_accs)\n",
        "    avg_prec = np.mean(all_precs)\n",
        "    avg_rec = np.mean(all_recs)\n",
        "    avg_f1 = np.mean(all_f1s)\n",
        "\n",
        "    print(\"\\nOverall Metrics:\")\n",
        "    print(f\"Average Accuracy: {avg_acc:.3f}\")\n",
        "    print(f\"Average Traning Accuracy: {avg_train_accuracies1:.3f}\")\n",
        "    print(f\"Average Validation Accuracy: {avg_val_accuracies2:.3f}\")\n",
        "    \n",
        "    print(f\"Average Precision: {avg_prec:.3f}\")\n",
        "    print(f\"Average Recall: {avg_rec:.3f}\")\n",
        "    print(f\"Average F1 Score: {avg_f1:.3f}\")\n",
        "\n",
        "    # Plotting average loss and accuracy\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(avg_train_losses, label='Average Train Loss', color=\"teal\")\n",
        "    plt.plot(avg_val_losses, label='Average Validation Loss', color=\"m\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(avg_train_accuracies, label='Average Train Accuracy', color=\"darkblue\")\n",
        "    plt.plot(avg_val_accuracies, label='Average Validation Accuracy', color=\"crimson\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "crossValidation(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluating the ResNet18\n",
        "\n",
        "def crossValidation(dataset, k=5, batch_size=32):\n",
        "    \"\"\"Performs k-fold cross-validation and generates confusion matrix and plots for all folds.\"\"\"\n",
        "\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    all_y_true, all_y_pred = [], []\n",
        "    all_train_losses, all_val_losses = [], []\n",
        "    all_train_accuracies, all_val_accuracies = [], []\n",
        "    all_accs, all_precs, all_recs, all_f1s = [], [], [], []\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(kf.split(dataset)):\n",
        "        print(f\"Fold {fold+1}/{k}\")\n",
        "        train_dataset = Subset(dataset, train_idx)\n",
        "        valid_dataset = Subset(dataset, valid_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        model_resnet = resnetModel(strategy='feature_extractor')\n",
        "        # model_resnet = resnetModel(strategy='fine_tune')\n",
        "        model_resnet, train_losses, val_losses, train_accuracies, val_accuracies = trainModel(model_resnet, train_loader, valid_loader)\n",
        "        y_true, y_pred, acc, prec, rec, f1 = evaluateModel(model_resnet, valid_loader, return_predictions=True)\n",
        "\n",
        "        all_train_losses.append(train_losses)\n",
        "        all_val_losses.append(val_losses)\n",
        "        all_train_accuracies.append(train_accuracies)\n",
        "        all_val_accuracies.append(val_accuracies)\n",
        "        all_accs.append(acc)\n",
        "        all_precs.append(prec)\n",
        "        all_recs.append(rec)\n",
        "        all_f1s.append(f1)\n",
        "\n",
        "        all_y_true.extend(y_true)\n",
        "        all_y_pred.extend(y_pred)\n",
        "\n",
        "        # Example image display for the current fold\n",
        "        example_loader = DataLoader(valid_dataset, batch_size=5, shuffle=True)\n",
        "        images, labels = next(iter(example_loader))\n",
        "        images = images.to(device)\n",
        "        denorm_images = denormalize(images.cpu(), [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        outputs = model_resnet(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 5, figsize=(20, 8))\n",
        "        for idx in range(5):\n",
        "            img = denorm_images[idx].permute(1, 2, 0).numpy()\n",
        "            pred_label = class_names[preds[idx].item()]\n",
        "            actual_label = class_names[labels[idx].item()]\n",
        "            axes[idx].imshow(img)\n",
        "            axes[idx].set_title(f\"Pred: {pred_label} | Actual: {actual_label}\", fontsize=8)\n",
        "            axes[idx].axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    # Generate and display the overall confusion matrix\n",
        "    print(\"Overall Confusion Matrix:\")\n",
        "    confusion_matrix_all = confusion_matrix(all_y_true, all_y_pred)\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    sns.heatmap(confusion_matrix_all, annot=True, fmt=\"d\", cmap=\"twilight\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Overall Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate and print average metrics\n",
        "    avg_train_losses = np.mean(np.array(all_train_losses), axis=0)\n",
        "    avg_val_losses = np.mean(np.array(all_val_losses), axis=0)\n",
        "    avg_train_accuracies = np.mean(np.array(all_train_accuracies), axis=0)\n",
        "    avg_val_accuracies = np.mean(np.array(all_val_accuracies), axis=0)\n",
        "    avg_train_accuracies1 = np.mean((all_train_accuracies))\n",
        "    avg_val_accuracies2 = np.mean((all_val_accuracies))\n",
        "    avg_acc = np.mean(all_accs)\n",
        "    avg_prec = np.mean(all_precs)\n",
        "    avg_rec = np.mean(all_recs)\n",
        "    avg_f1 = np.mean(all_f1s)\n",
        "\n",
        "    print(\"\\nOverall Metrics:\")\n",
        "    print(f\"Average Accuracy: {avg_acc:.3f}\")\n",
        "    print(f\"Average Traning Accuracy: {avg_train_accuracies1:.3f}\")\n",
        "    print(f\"Average Validation Accuracy: {avg_val_accuracies2:.3f}\")\n",
        "    print(f\"Average Precision: {avg_prec:.3f}\")\n",
        "    print(f\"Average Recall: {avg_rec:.3f}\")\n",
        "    print(f\"Average F1 Score: {avg_f1:.3f}\")\n",
        "\n",
        "    # Plotting average loss and accuracy\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(avg_train_losses, label='Average Train Loss', color=\"teal\")\n",
        "    plt.plot(avg_val_losses, label='Average Validation Loss', color=\"m\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(avg_train_accuracies, label='Average Train Accuracy', color=\"darkblue\")\n",
        "    plt.plot(avg_val_accuracies, label='Average Validation Accuracy', color=\"crimson\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "crossValidation(train_val_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
